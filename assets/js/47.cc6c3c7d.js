(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{340:function(e,t,n){"use strict";n.r(t);var v=n(11),_=Object(v.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("center",[t("h1",[e._v("信息隐藏小组")])]),e._v(" "),t("p",[e._v("本小组主要研究信息隐藏领域的内的隐写和水印。具体研究包括传统隐写，构造式隐写，鲁棒隐写，屏摄水印，3D水印等多个方向。构造式隐写与传统隐写的区别在于，传统隐写在现有载体中嵌入秘密信息，构造式隐写是生成式的，载体在生成时便自带秘密信息。鲁棒隐写相比于传统隐写更具有鲁棒性，在有损信道中传输后，仍能有效提取秘密消息，同时具有安全性。本组的研究主要从“正向”一隐藏和“反向”一一攻击，两个方向同步进行，以此促进信息隐藏研究的螺旋上升。")]),e._v(" "),t("center",[t("h1",[e._v("多媒体取证小组")])]),e._v(" "),t("p",[e._v("主要研究方向为多媒体主动取证与被动取证、DeepFak检测等。现今社交媒体中存在大量的虚假新闻、虚假图片、虚假人脸等，对用户感知、舆情传播具有高危险性、高欺骗性，虚假媒体若不加鉴别广泛传播，可能对社会风气造成恶劣影响。本小组通过研究图像、视频与多模态的被动取证技术，鉴别社交媒体上的虚假新闻，结合图像、文本与视频各自与相互的特征，更好实现具有高实用性的虚假新闻检测。同时，研究鲁棒信息隐藏技术在多媒体取证方向上的应用，例如图像免疫、图像抗裁剪等等。本小组也研究DeepFake检测技术，及更多由生成式网络带来的新型多媒体安全攻防问题。")]),e._v(" "),t("center",[t("h1",[e._v("AI安全小组")])]),e._v(" "),t("p",[e._v("主要研究人工智能中的安全问题包括但不限于对抗样本，神经网络后门，神经网络模型水印等。比如在模型训练阶段，可以通过篡改训练数据集来实现目标模型植入后门，受此攻击影响的模型对于正常样本依旧可以做出正确判断，但是对于特定输入（带有后门触发标记）的样本就会做出错误判断。除此之外在模型推断阶段，存在对抗样本攻击，通过修改输入样本来即使模型做出错误判断。本组研究主要涉及在神经网络模型在训练及部署阶段可能存在的安全漏洞以及对应防御方法。")]),e._v(" "),t("center",[t("h1",[e._v("智能机器人小组")])]),e._v("\n主要研究社交网络虚拟用户的社交内容生成以及社交行为预测与检测问题，包括但不限于：个性化社交文本生成、虚拟用户社交行为及内容检测、群聊场景下回复选择与生成、图片描述与评论生成、基于社交网络内容和行为的信息隐藏等。本组现阶段主要围绕多媒体社交内容生成类问题，以及各种虚假用户生成内容、机器人行为检测分类问题展开研究。下阶段将围绕个性化、情绪化生成式机器人在多场景下的构造问题，多媒体内容评论生成问题进行进一步研究。\n")],1)}),[],!1,null,null,null);t.default=_.exports}}]);