(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{277:function(t,e,s){t.exports=s.p+"assets/img/FND-CLIP_2.0e3ac60b.png"},313:function(t,e,s){t.exports=s.p+"assets/img/FND-CLIP_1.fbf6a356.png"},314:function(t,e,s){t.exports=s.p+"assets/img/FND-CLIP_3.1247a89c.png"},315:function(t,e,s){t.exports=s.p+"assets/img/FND-CLIP_4.1a63526a.png"},349:function(t,e,s){"use strict";s.r(e);var a=s(11),i=Object(a.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("head",[e("link",{attrs:{href:"http://cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css",rel:"stylesheet"}})]),t._v(" "),e("section",{staticClass:"hero"},[e("div",{staticClass:"hero-body"},[e("div",{staticClass:"container is-max-desktop"},[e("div",{staticClass:"columns is-centered"},[e("div",{staticClass:"column has-text-centered"},[e("h1",{staticClass:"title is-1 publication-title"},[t._v("Multimodal Fake News Detection via CLIP-Guided Learning")]),t._v(" "),e("h2",{staticClass:"title is-4 publication-title"},[t._v("ICME 2023")]),t._v(" "),e("div",{staticClass:"is-size-5 publication-authors"},[e("span",{staticClass:"author-block"},[t._v("\n              Yangming Zhou, ")]),t._v(" "),e("span",{staticClass:"author-block"},[t._v("\n              Qichao Ying, ")]),t._v(" "),e("span",{staticClass:"author-block"},[t._v("\n              Zhenxing Qian"),e("sup",[t._v("*")]),t._v(", \n            ")]),t._v(" "),e("span",{staticClass:"author-block"},[t._v("\n              Sheng Li, \n            ")]),t._v(" "),e("span",{staticClass:"author-block"},[t._v("\n              Xinpeng Zhang\n            ")])]),t._v(" "),e("div",{staticClass:"is-size-5 publication-authors"},[e("div",[e("span",{staticClass:"author-block"},[e("sup",[t._v("1")]),t._v("School of Computer Science, Fudan University")])])]),t._v(" "),e("div",{staticClass:"column has-text-centered"},[e("div",{staticClass:"publication-links"},[e("span",{staticClass:"link-block"},[e("a",{staticClass:"external-link button is-normal is-rounded is-dark",attrs:{href:"https://arxiv.org/pdf/2205.14304.pdf"}},[e("span",{staticClass:"icon"},[e("i",{staticClass:"fas fa-file-pdf"})]),t._v(" "),e("span",[t._v("Paper")])])]),t._v(" "),e("span",{staticClass:"link-block"},[e("a",{staticClass:"external-link button is-normal is-rounded is-dark",attrs:{href:"https://arxiv.org/abs/2205.14304"}},[e("span",{staticClass:"icon"},[e("i",{staticClass:"ai ai-arxiv"})]),t._v(" "),e("span",[t._v("arXiv")])])]),t._v(" "),e("span",{staticClass:"link-block"},[e("a",{staticClass:"external-link button is-normal is-rounded is-dark",attrs:{href:"https://github.com/zhouyangming/FND-CLIP-Fake-News-Detection"}},[e("span",{staticClass:"icon"},[e("i",{staticClass:"fab fa-github"})]),t._v(" "),e("span",[t._v("Code")])])])])])])])])])]),t._v(" "),e("section",{staticClass:"hero"},[e("div",{staticClass:"hero-body"},[e("div",{staticClass:"container is-max-desktop"},[e("div",{staticClass:"columns is-centered"},[e("div",{staticClass:"column has-text-centered"},[e("img",{attrs:{src:s(313)}}),t._v(" "),e("h2",{staticClass:"subtitle has-text-centered"},[e("span",{staticClass:"dnerf"},[t._v("An example of FND-CLIP detecting fake news on the Weibo dataset")])]),t._v(" "),e("h2",{staticClass:"title publication-title"},[t._v("Abstract")])]),t._v(" "),e("p",[t._v("\n                Fake news detection (FND) has attracted much research interests in social forensics. Many existing approaches introduce tailored attention mechanisms to fuse unimodal features. However, they ignore the impact of cross-modal similarity between modalities. Meanwhile, the potential of pretrained multimodal feature learning models in FND has not been well exploited. This paper proposes an FND-CLIP framework, i.e., a multimodal Fake News Detection network based on Contrastive Language-Image Pretraining (CLIP). FND-CLIP extracts the deep representations together from news using two unimodal encoders and two pair-wise CLIP encoders. The CLIP-generated multimodal features are weighted by CLIP similarity of the two modalities. We also introduce a modality-wise attention module to aggregate the features. Extensive experiments are conducted and the results indicate that the proposed framework has a better capability in mining crucial features for fake news detection. The proposed FND-CLIP can achieve better performances than previous works on three typical fake news datasets.\n                ")]),t._v(" "),e("div",{staticClass:"column has-text-centered"},[e("h2",{staticClass:"title publication-title"},[t._v("Method")]),t._v(" "),e("img",{attrs:{src:s(277)}}),t._v(" "),e("h2",{staticClass:"subtitle has-text-centered"},[e("span",{staticClass:"dnerf"},[t._v("The network architecture of FND-CLIP")])])]),t._v(" "),e("p",[t._v("\n                    We propose FND-CLIP, a multi-modal fake news detection model that employs the CLIP model to address cross-modal ambiguity issues. In addition to utilizing CLIP, BERT, and ResNet pre-trained models for single-modal feature encoding, this article also employs CLIP to generate multi-modal features. These multi-modal features complement the single-modal ones, enhancing their semantic representations. CLIP leverages a vast dataset of image-text pairs for semantic extraction, eliminating emotions, noise, and irrelevant features associated with image and text matching.\n                ")]),t._v(" "),e("div",{staticClass:"row"},[e("div",{staticClass:"column has-text-centered"},[e("img",{attrs:{src:s(314),height:"260px"}}),t._v(" "),e("h2",{staticClass:"subtitle has-text-centered"},[e("span",{staticClass:"dnerf"},[t._v("Fusion Adjustment Module")])])]),t._v(" "),e("div",{staticClass:"column has-text-centered"},[e("img",{attrs:{src:s(315),height:"260px"}}),t._v(" "),e("h2",{staticClass:"subtitle has-text-centered"},[e("span",{staticClass:"dnerf"},[t._v("Modality Attention Module")])])])]),t._v(" "),e("p",[t._v("\n                    When collaborating with single-modal features, we can comprehensively scrutinize news from various aspects. However, merely combining CLIP-based features into multi-modal features could lead to unreliable information due to the presence of additional ambiguous information within the features. To mitigate this ambiguity, we devised a fusion adjustment module. This module adjusts the strength of fused features by measuring the cosine similarity between text and image features provided by CLIP.\n                ")]),t._v(" "),e("p",[t._v("\n                    To further balance the impact of different modalities on news detection, drawing inspiration from SE-Net, we designed a modality attention module. This module employs two fully connected layers to learn relationships between modalities and applies these relationships to weight the feature values of each modality. This step allows the network to adaptively learn the importance of different modalities, thereby enhancing the network's performance.\n                ")])])])])]),t._v(" "),e("section",{staticClass:"section"},[e("div",{staticClass:"container is-max-desktop"},[e("p",[t._v("If you like the project, please show your support by "),e("a",{attrs:{href:"https://github.com/zhouyangming/FND-CLIP-Fake-News-Detection"}},[t._v("leaving a star")]),t._v(" ðŸŒŸ !")])])])])}),[],!1,null,null,null);e.default=i.exports}}]);