<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>复旦MAS实验室</title>
    <meta name="generator" content="VuePress 1.9.10">
    <script type="text/javascript" src="/js/echarts.js"></script>
    <meta name="description" content=" ">
    
    <link rel="preload" href="/assets/css/0.styles.f9ca9fd5.css" as="style"><link rel="preload" href="/assets/js/app.e6a34b8f.js" as="script"><link rel="preload" href="/assets/js/2.cfd0c35e.js" as="script"><link rel="preload" href="/assets/js/1.bfcb5427.js" as="script"><link rel="preload" href="/assets/js/18.d153fe0f.js" as="script"><link rel="prefetch" href="/assets/js/10.3622560d.js"><link rel="prefetch" href="/assets/js/11.6b44e522.js"><link rel="prefetch" href="/assets/js/12.72b8e94e.js"><link rel="prefetch" href="/assets/js/13.7c7e6a93.js"><link rel="prefetch" href="/assets/js/14.016425de.js"><link rel="prefetch" href="/assets/js/15.444a89c9.js"><link rel="prefetch" href="/assets/js/16.0a20489d.js"><link rel="prefetch" href="/assets/js/17.48976dca.js"><link rel="prefetch" href="/assets/js/19.7b09d5b5.js"><link rel="prefetch" href="/assets/js/20.5764d385.js"><link rel="prefetch" href="/assets/js/21.20c6c3b0.js"><link rel="prefetch" href="/assets/js/22.75d179e8.js"><link rel="prefetch" href="/assets/js/23.e82937cc.js"><link rel="prefetch" href="/assets/js/24.52f23f64.js"><link rel="prefetch" href="/assets/js/25.a5853666.js"><link rel="prefetch" href="/assets/js/26.fc866b47.js"><link rel="prefetch" href="/assets/js/27.0d0269d2.js"><link rel="prefetch" href="/assets/js/28.d8d3f593.js"><link rel="prefetch" href="/assets/js/29.d8be3757.js"><link rel="prefetch" href="/assets/js/3.c9a27143.js"><link rel="prefetch" href="/assets/js/30.8153edc1.js"><link rel="prefetch" href="/assets/js/31.5a203798.js"><link rel="prefetch" href="/assets/js/32.3e45a361.js"><link rel="prefetch" href="/assets/js/33.2209cdfb.js"><link rel="prefetch" href="/assets/js/34.192fbb31.js"><link rel="prefetch" href="/assets/js/35.95e8af36.js"><link rel="prefetch" href="/assets/js/36.0f686869.js"><link rel="prefetch" href="/assets/js/37.36f48c3e.js"><link rel="prefetch" href="/assets/js/38.de844197.js"><link rel="prefetch" href="/assets/js/39.83b1a2e3.js"><link rel="prefetch" href="/assets/js/4.40bd94c9.js"><link rel="prefetch" href="/assets/js/40.5f0bac0d.js"><link rel="prefetch" href="/assets/js/41.f86a18ca.js"><link rel="prefetch" href="/assets/js/42.308b6e60.js"><link rel="prefetch" href="/assets/js/43.ecf0963d.js"><link rel="prefetch" href="/assets/js/44.32d7d615.js"><link rel="prefetch" href="/assets/js/45.9e8a7b78.js"><link rel="prefetch" href="/assets/js/46.5b2a1129.js"><link rel="prefetch" href="/assets/js/47.cc6c3c7d.js"><link rel="prefetch" href="/assets/js/48.7ac8c3cf.js"><link rel="prefetch" href="/assets/js/49.dd530fb2.js"><link rel="prefetch" href="/assets/js/5.70f434a7.js"><link rel="prefetch" href="/assets/js/50.d7be7578.js"><link rel="prefetch" href="/assets/js/51.a6821948.js"><link rel="prefetch" href="/assets/js/52.6186d745.js"><link rel="prefetch" href="/assets/js/53.1bc38db5.js"><link rel="prefetch" href="/assets/js/54.7e3e5c99.js"><link rel="prefetch" href="/assets/js/55.b19a7120.js"><link rel="prefetch" href="/assets/js/6.ed9ec4c5.js"><link rel="prefetch" href="/assets/js/7.b07a370b.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.657e42b7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f9ca9fd5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar custom-navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/MAS.png" class="logo"> <span class="site-name can-hide">Fudan MAS</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/research/FND-CLIP.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  en-US
</a></li><li class="dropdown-item"><!----> <a href="/zh/" class="nav-link">
  zh-CN
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/research/FND-CLIP.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  en-US
</a></li><li class="dropdown-item"><!----> <a href="/zh/" class="nav-link">
  zh-CN
</a></li></ul></div></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><head><link href="http://cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet"></head> <section class="hero"><div class="hero-body"><div class="container is-max-desktop"><div class="columns is-centered"><div class="column has-text-centered"><h1 class="title is-1 publication-title">Multimodal Fake News Detection via CLIP-Guided Learning</h1> <h2 class="title is-4 publication-title">ICME 2023</h2> <div class="is-size-5 publication-authors"><span class="author-block">
              Yangming Zhou, </span> <span class="author-block">
              Qichao Ying, </span> <span class="author-block">
              Zhenxing Qian<sup>*</sup>, 
            </span> <span class="author-block">
              Sheng Li, 
            </span> <span class="author-block">
              Xinpeng Zhang
            </span></div> <div class="is-size-5 publication-authors"><div><span class="author-block"><sup>1</sup>School of Computer Science, Fudan University</span></div></div> <div class="column has-text-centered"><div class="publication-links"><span class="link-block"><a href="https://arxiv.org/pdf/2205.14304.pdf" class="external-link button is-normal is-rounded is-dark"><span class="icon"><i class="fas fa-file-pdf"></i></span> <span>Paper</span></a></span> <span class="link-block"><a href="https://arxiv.org/abs/2205.14304" class="external-link button is-normal is-rounded is-dark"><span class="icon"><i class="ai ai-arxiv"></i></span> <span>arXiv</span></a></span> <span class="link-block"><a href="https://github.com/zhouyangming/FND-CLIP-Fake-News-Detection" class="external-link button is-normal is-rounded is-dark"><span class="icon"><i class="fab fa-github"></i></span> <span>Code</span></a></span></div></div></div></div></div></div></section> <section class="hero"><div class="hero-body"><div class="container is-max-desktop"><div class="columns is-centered"><div class="column has-text-centered"><img src="/assets/img/FND-CLIP_1.fbf6a356.png"> <h2 class="subtitle has-text-centered"><span class="dnerf">An example of FND-CLIP detecting fake news on the Weibo dataset</span></h2> <h2 class="title publication-title">Abstract</h2></div> <p>
                Fake news detection (FND) has attracted much research interests in social forensics. Many existing approaches introduce tailored attention mechanisms to fuse unimodal features. However, they ignore the impact of cross-modal similarity between modalities. Meanwhile, the potential of pretrained multimodal feature learning models in FND has not been well exploited. This paper proposes an FND-CLIP framework, i.e., a multimodal Fake News Detection network based on Contrastive Language-Image Pretraining (CLIP). FND-CLIP extracts the deep representations together from news using two unimodal encoders and two pair-wise CLIP encoders. The CLIP-generated multimodal features are weighted by CLIP similarity of the two modalities. We also introduce a modality-wise attention module to aggregate the features. Extensive experiments are conducted and the results indicate that the proposed framework has a better capability in mining crucial features for fake news detection. The proposed FND-CLIP can achieve better performances than previous works on three typical fake news datasets.
                </p> <div class="column has-text-centered"><h2 class="title publication-title">Method</h2> <img src="/assets/img/FND-CLIP_2.0e3ac60b.png"> <h2 class="subtitle has-text-centered"><span class="dnerf">The network architecture of FND-CLIP</span></h2></div> <p>
                    We propose FND-CLIP, a multi-modal fake news detection model that employs the CLIP model to address cross-modal ambiguity issues. In addition to utilizing CLIP, BERT, and ResNet pre-trained models for single-modal feature encoding, this article also employs CLIP to generate multi-modal features. These multi-modal features complement the single-modal ones, enhancing their semantic representations. CLIP leverages a vast dataset of image-text pairs for semantic extraction, eliminating emotions, noise, and irrelevant features associated with image and text matching.
                </p> <div class="row"><div class="column has-text-centered"><img src="/assets/img/FND-CLIP_3.1247a89c.png" height="260px"> <h2 class="subtitle has-text-centered"><span class="dnerf">Fusion Adjustment Module</span></h2></div> <div class="column has-text-centered"><img src="/assets/img/FND-CLIP_4.1a63526a.png" height="260px"> <h2 class="subtitle has-text-centered"><span class="dnerf">Modality Attention Module</span></h2></div></div> <p>
                    When collaborating with single-modal features, we can comprehensively scrutinize news from various aspects. However, merely combining CLIP-based features into multi-modal features could lead to unreliable information due to the presence of additional ambiguous information within the features. To mitigate this ambiguity, we devised a fusion adjustment module. This module adjusts the strength of fused features by measuring the cosine similarity between text and image features provided by CLIP.
                </p> <p>
                    To further balance the impact of different modalities on news detection, drawing inspiration from SE-Net, we designed a modality attention module. This module employs two fully connected layers to learn relationships between modalities and applies these relationships to weight the feature values of each modality. This step allows the network to adaptively learn the importance of different modalities, thereby enhancing the network's performance.
                </p></div></div></div></section> <section class="section"><div class="container is-max-desktop"><p>If you like the project, please show your support by <a href="https://github.com/zhouyangming/FND-CLIP-Fake-News-Detection">leaving a star</a> 🌟 !</p></div></section></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.e6a34b8f.js" defer></script><script src="/assets/js/2.cfd0c35e.js" defer></script><script src="/assets/js/1.bfcb5427.js" defer></script><script src="/assets/js/18.d153fe0f.js" defer></script>
  </body>
</html>
