<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>复旦MAS实验室</title>
    <meta name="generator" content="VuePress 1.9.10">
    <script type="text/javascript" src="/js/echarts.js"></script>
    <meta name="description" content=" ">
    
    <link rel="preload" href="/assets/css/0.styles.f9ca9fd5.css" as="style"><link rel="preload" href="/assets/js/app.e6a34b8f.js" as="script"><link rel="preload" href="/assets/js/2.cfd0c35e.js" as="script"><link rel="preload" href="/assets/js/1.bfcb5427.js" as="script"><link rel="preload" href="/assets/js/28.d8d3f593.js" as="script"><link rel="prefetch" href="/assets/js/10.3622560d.js"><link rel="prefetch" href="/assets/js/11.6b44e522.js"><link rel="prefetch" href="/assets/js/12.72b8e94e.js"><link rel="prefetch" href="/assets/js/13.7c7e6a93.js"><link rel="prefetch" href="/assets/js/14.016425de.js"><link rel="prefetch" href="/assets/js/15.444a89c9.js"><link rel="prefetch" href="/assets/js/16.0a20489d.js"><link rel="prefetch" href="/assets/js/17.48976dca.js"><link rel="prefetch" href="/assets/js/18.d153fe0f.js"><link rel="prefetch" href="/assets/js/19.7b09d5b5.js"><link rel="prefetch" href="/assets/js/20.5764d385.js"><link rel="prefetch" href="/assets/js/21.20c6c3b0.js"><link rel="prefetch" href="/assets/js/22.75d179e8.js"><link rel="prefetch" href="/assets/js/23.e82937cc.js"><link rel="prefetch" href="/assets/js/24.52f23f64.js"><link rel="prefetch" href="/assets/js/25.a5853666.js"><link rel="prefetch" href="/assets/js/26.fc866b47.js"><link rel="prefetch" href="/assets/js/27.0d0269d2.js"><link rel="prefetch" href="/assets/js/29.d8be3757.js"><link rel="prefetch" href="/assets/js/3.c9a27143.js"><link rel="prefetch" href="/assets/js/30.8153edc1.js"><link rel="prefetch" href="/assets/js/31.5a203798.js"><link rel="prefetch" href="/assets/js/32.3e45a361.js"><link rel="prefetch" href="/assets/js/33.2209cdfb.js"><link rel="prefetch" href="/assets/js/34.192fbb31.js"><link rel="prefetch" href="/assets/js/35.95e8af36.js"><link rel="prefetch" href="/assets/js/36.0f686869.js"><link rel="prefetch" href="/assets/js/37.36f48c3e.js"><link rel="prefetch" href="/assets/js/38.de844197.js"><link rel="prefetch" href="/assets/js/39.83b1a2e3.js"><link rel="prefetch" href="/assets/js/4.40bd94c9.js"><link rel="prefetch" href="/assets/js/40.5f0bac0d.js"><link rel="prefetch" href="/assets/js/41.f86a18ca.js"><link rel="prefetch" href="/assets/js/42.308b6e60.js"><link rel="prefetch" href="/assets/js/43.ecf0963d.js"><link rel="prefetch" href="/assets/js/44.32d7d615.js"><link rel="prefetch" href="/assets/js/45.9e8a7b78.js"><link rel="prefetch" href="/assets/js/46.5b2a1129.js"><link rel="prefetch" href="/assets/js/47.cc6c3c7d.js"><link rel="prefetch" href="/assets/js/48.7ac8c3cf.js"><link rel="prefetch" href="/assets/js/49.dd530fb2.js"><link rel="prefetch" href="/assets/js/5.70f434a7.js"><link rel="prefetch" href="/assets/js/50.d7be7578.js"><link rel="prefetch" href="/assets/js/51.a6821948.js"><link rel="prefetch" href="/assets/js/52.6186d745.js"><link rel="prefetch" href="/assets/js/53.1bc38db5.js"><link rel="prefetch" href="/assets/js/54.7e3e5c99.js"><link rel="prefetch" href="/assets/js/55.b19a7120.js"><link rel="prefetch" href="/assets/js/6.ed9ec4c5.js"><link rel="prefetch" href="/assets/js/7.b07a370b.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.657e42b7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f9ca9fd5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar custom-navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/MAS.png" class="logo"> <span class="site-name can-hide">Fudan MAS</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/research/RetouchingFFHQ.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  en-US
</a></li><li class="dropdown-item"><!----> <a href="/zh/" class="nav-link">
  zh-CN
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/research/RetouchingFFHQ.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  en-US
</a></li><li class="dropdown-item"><!----> <a href="/zh/" class="nav-link">
  zh-CN
</a></li></ul></div></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><head><link href="http://cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet"></head> <section class="hero"><div class="hero-body"><div class="container is-max-desktop"><div class="columns is-centered"><div class="column has-text-centered"><h1 class="title is-1 publication-title">RetouchingFFHQ: A Large-scale Dataset for Fine-grained Face Retouching Detection</h1> <h2 class="title is-4 publication-title">ACM MM 2023</h2> <div class="is-size-5 publication-authors"><span class="author-block">
              Qichao Ying<sup>1</sup>, </span> <span class="author-block">
              Jiaxin Liu<sup>1</sup>, </span> <span class="author-block">
              Sheng Li<sup>1,★</sup>, 
            </span> <span class="author-block">
              Haisheng Xu<sup>2</sup>, 
            </span> <span class="author-block">
              Zhenxing Qian<sup>1,*</sup></span> <span class="author-block">
              Xinpeng Zhang<sup>1</sup></span></div> <div class="is-size-5 publication-authors"><div><span class="author-block"><sup>1</sup>School of Computer Science, Fudan University, Shanghai, China</span></div> <div><span class="author-block"><sup>2</sup>NVIDIA, Shanghai, China</span></div></div> <div class="column has-text-centered"><div class="publication-links"><span class="link-block"><a href="https://arxiv.org/pdf/2307.10642" class="external-link button is-normal is-rounded is-dark"><span class="icon"><i class="fas fa-file-pdf"></i></span> <span>Paper</span></a></span> <span class="link-block"><a href="https://github.com/yingqichao/retouching_FFHQ_detection" class="external-link button is-normal is-rounded is-dark"><span class="icon"><i class="fab fa-github"></i></span> <span>Code</span></a></span></div> <p>
            Dataset Aquisition Click <a href="/Application_RetouchingFFHQ_new.pdf">&quot;Application Form&quot;</a>, fill in necessary information and send the PDF to fudanmaslab@gmail.com, with haoyuewang23@m.fudan.edu.cn and lisheng@fudan.edu.cn copied. Thank you!
          </p></div></div></div></div></div></section> <section class="hero"><div class="hero-body"><div class="container is-max-desktop"><div class="columns is-centered"><div class="column has-text-centered"><img src="/assets/img/RetouchingFFHQ_1.4ab38dd8.png"> <h2 class="subtitle has-text-centered"><span class="dnerf">Examples of RetouchingFFHQ, a fine-grained face retouching dataset containing over half a million images</span></h2> <h2 class="title publication-title">Abstract</h2></div> <p>
                The widespread use of face retouching filters on short-video platforms has raised concerns about the authenticity of digital appearances and the impact of deceptive advertising. To address these issues, there is a pressing need to develop advanced face retouching techniques. However, the lack of large-scale and fine-grained face retouching datasets has been a major obstacle to progress in this field. In this paper, we introduce RetouchingFFHQ, a large-scale and fine-grained face retouching dataset that contains over half a million conditionally-retouched images. RetouchingFFHQ stands out from previous datasets due to its large scale, high quality, fine-grainedness, and customization. By including four typical types of face retouching operations and different retouching levels, we extend the binary face retouching detection into a fine-grained, multi-retouching type, and multi-retouching level estimation problem. Additionally, we propose a Multi-granularity Attention Module (MAM) as a plugin for CNN backbones for enhanced cross-scale representation learning. Extensive experiments using different baselines as well as our proposed method on RetouchingFFHQ show decent performance on face retouching detection.
                </p> <div class="column has-text-centered"><h2 class="title publication-title">Method</h2> <img src="/assets/img/RetouchingFFHQ_2.d5307157.png"> <h2 class="subtitle has-text-centered"><span class="dnerf">Network Design of the proposed MAM</span></h2></div> <p>
                    We investigate how humans make predictions without reference to the original faces by scrutinizing the retouched images. Besides geometric distortion or noise-level artifacts left by retouching algorithms, we find that the other critical factor relies on the features that can be learnt from multiple granularities. For instance, given an image with large eyes, a closer look on the eyes would easily lead to the conclusion that the image has undergone eye-enlarging. However, further considering the large occupation of the face in the image as well as the reasonable ratio of eyes and face, we would reconsider the image as not being eye-enlarged. Similar phenomenon could also be observed on other retouching types. Besides, there can exist a non-negligible amount of spatial redundancy within the visual representations. For example, the background and skin regions can be reduced into two tokenized representation containing the averaged statistic of lightning condition and sharpness. 
                </p> <p>
                    For spatial redundancy reduction, we propose the adaptive token clustering method. For enhanced multi-granularity representation learning, we employ a lightweight two-layered Transformer encoder to analyze and compare multi-granularity information for detection.
                </p></div></div></div></section> <section id="BibTeX" class="section"><div class="container is-max-desktop content"><h2 class="title publication-title">BibTeX</h2> <pre>        <code>
        @article{ying2023retouching,
        title={RetouchingFFHQ: A Large-scale Dataset for Fine-grained Face Retouching Detection},
        author={Qichao, Ying and Jiaxin, Liu and Sheng, Li and Haisheng, Xu and Zhenxing, Qian and Xinpeng, Zhang},
        journal={Proceedings of the 31th ACM International Conference on Multimedia},
        year={2023}
        }
        </code>
    </pre></div></section></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.e6a34b8f.js" defer></script><script src="/assets/js/2.cfd0c35e.js" defer></script><script src="/assets/js/1.bfcb5427.js" defer></script><script src="/assets/js/28.d8d3f593.js" defer></script>
  </body>
</html>
