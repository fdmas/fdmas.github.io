<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>复旦MAS实验室</title>
    <meta name="generator" content="VuePress 1.9.10">
    <script type="text/javascript" src="/js/echarts.js"></script>
    <meta name="description" content=" ">
    
    <link rel="preload" href="/assets/css/0.styles.f9ca9fd5.css" as="style"><link rel="preload" href="/assets/js/app.e6a34b8f.js" as="script"><link rel="preload" href="/assets/js/2.cfd0c35e.js" as="script"><link rel="preload" href="/assets/js/1.bfcb5427.js" as="script"><link rel="preload" href="/assets/js/35.95e8af36.js" as="script"><link rel="prefetch" href="/assets/js/10.3622560d.js"><link rel="prefetch" href="/assets/js/11.6b44e522.js"><link rel="prefetch" href="/assets/js/12.72b8e94e.js"><link rel="prefetch" href="/assets/js/13.7c7e6a93.js"><link rel="prefetch" href="/assets/js/14.016425de.js"><link rel="prefetch" href="/assets/js/15.444a89c9.js"><link rel="prefetch" href="/assets/js/16.0a20489d.js"><link rel="prefetch" href="/assets/js/17.48976dca.js"><link rel="prefetch" href="/assets/js/18.d153fe0f.js"><link rel="prefetch" href="/assets/js/19.7b09d5b5.js"><link rel="prefetch" href="/assets/js/20.5764d385.js"><link rel="prefetch" href="/assets/js/21.20c6c3b0.js"><link rel="prefetch" href="/assets/js/22.75d179e8.js"><link rel="prefetch" href="/assets/js/23.e82937cc.js"><link rel="prefetch" href="/assets/js/24.52f23f64.js"><link rel="prefetch" href="/assets/js/25.a5853666.js"><link rel="prefetch" href="/assets/js/26.fc866b47.js"><link rel="prefetch" href="/assets/js/27.0d0269d2.js"><link rel="prefetch" href="/assets/js/28.d8d3f593.js"><link rel="prefetch" href="/assets/js/29.d8be3757.js"><link rel="prefetch" href="/assets/js/3.c9a27143.js"><link rel="prefetch" href="/assets/js/30.8153edc1.js"><link rel="prefetch" href="/assets/js/31.5a203798.js"><link rel="prefetch" href="/assets/js/32.3e45a361.js"><link rel="prefetch" href="/assets/js/33.2209cdfb.js"><link rel="prefetch" href="/assets/js/34.192fbb31.js"><link rel="prefetch" href="/assets/js/36.0f686869.js"><link rel="prefetch" href="/assets/js/37.36f48c3e.js"><link rel="prefetch" href="/assets/js/38.de844197.js"><link rel="prefetch" href="/assets/js/39.83b1a2e3.js"><link rel="prefetch" href="/assets/js/4.40bd94c9.js"><link rel="prefetch" href="/assets/js/40.5f0bac0d.js"><link rel="prefetch" href="/assets/js/41.f86a18ca.js"><link rel="prefetch" href="/assets/js/42.308b6e60.js"><link rel="prefetch" href="/assets/js/43.ecf0963d.js"><link rel="prefetch" href="/assets/js/44.32d7d615.js"><link rel="prefetch" href="/assets/js/45.9e8a7b78.js"><link rel="prefetch" href="/assets/js/46.5b2a1129.js"><link rel="prefetch" href="/assets/js/47.cc6c3c7d.js"><link rel="prefetch" href="/assets/js/48.7ac8c3cf.js"><link rel="prefetch" href="/assets/js/49.dd530fb2.js"><link rel="prefetch" href="/assets/js/5.70f434a7.js"><link rel="prefetch" href="/assets/js/50.d7be7578.js"><link rel="prefetch" href="/assets/js/51.a6821948.js"><link rel="prefetch" href="/assets/js/52.6186d745.js"><link rel="prefetch" href="/assets/js/53.1bc38db5.js"><link rel="prefetch" href="/assets/js/54.7e3e5c99.js"><link rel="prefetch" href="/assets/js/55.b19a7120.js"><link rel="prefetch" href="/assets/js/6.ed9ec4c5.js"><link rel="prefetch" href="/assets/js/7.b07a370b.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.657e42b7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f9ca9fd5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar custom-navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/MAS.png" class="logo"> <span class="site-name can-hide">Fudan MAS</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/research/VCMaster.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  en-US
</a></li><li class="dropdown-item"><!----> <a href="/zh/" class="nav-link">
  zh-CN
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Languages</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Languages</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/research/VCMaster.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  en-US
</a></li><li class="dropdown-item"><!----> <a href="/zh/" class="nav-link">
  zh-CN
</a></li></ul></div></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><head><link href="http://cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet"></head> <section class="hero"><div class="hero-body"><div class="container is-max-desktop"><div class="columns is-centered"><div class="column has-text-centered"><h1 class="title is-1 publication-title">VCMaster: Generating Diverse and Fluent Live Video Comments Based on Multimodal Contexts</h1> <h2 class="title is-4 publication-title">ACM MM 2023</h2> <div class="is-size-5 publication-authors"><span class="author-block">
              Manman Zhang, </span> <span class="author-block">
              Ge Luo, </span> <span class="author-block">
              Yuchen Ma, 
            </span> <span class="author-block">
              Sheng Li, 
            </span> <span class="author-block">
              Zhenxing Qian<sup>*</sup>, 
            </span> <span class="author-block">
              Xinpeng Zhang<sup>*</sup>.
            </span></div> <div class="is-size-5 publication-authors"><div><span class="author-block">Fudan University, Shanghai, China</span></div></div> <div class="column has-text-centered"><div class="publication-links"></div></div></div></div></div></div></section> <section class="hero"><div class="hero-body"><div class="container is-max-desktop"><div class="columns is-centered"><div class="column has-text-centered"><h2 class="title publication-title">Abstract</h2></div> <p>
                Live video commenting, or &quot;bullet screen,&quot; is a popular social style on video platforms. Automatic live commenting has been explored as a promising approach to enhance the appeal of videos. However, existing methods neglect the diversity of generated sentences, limiting the potential to obtain human-like comments. In this paper, we introduce a novel framework called &quot;VCMaster&quot; for multimodal live video comments generation, which balances the diversity and quality of generated comments to create human-like sentences. We involve images, subtitles, and contextual comments as inputs to better understand complex video contexts. Then, we propose an effective Hierarchical Cross-Fusion Decoder to integrate high-quality trimodal feature representations by cross-fusing critical information from previous layers. Additionally, we develop a Sentence-Level Contrastive Loss to enlarge the distance between generated and contextual comments by contrastive learning. It helps the model to avoid the pitfall of simply imitating provided contextual comments and losing creativity, encouraging the model to achieve more diverse comments while maintaining high quality. We also construct a large-scale multimodal live video comments dataset with 292,507 comments and three sub-datasets that cover nine general categories. Extensive experiments demonstrate that our model achieves a level of human-like language expression and remarkably fluent, diverse, and engaging generated comments compared to baselines.
                </p> <div class="column has-text-centered"><h2 class="title publication-title">Method</h2> <img src="/assets/img/VCMaster_1.d1f78351.png"> <h2 class="subtitle has-text-centered"><span class="dnerf">Overview of VCMaster, the proposed Multimodal Live Video Comments Generation model that generates fluent and diverse human-like comments based on video frames, subtitles, and contextual comments. <common-latexDisplay>\mathcal{L}_{TCL}</common-latexDisplay> and <common-latexDisplay>\mathcal{L}_{SCL}</common-latexDisplay> aim to enlarge the distance between tokens and sentences, improving the diversity of generated comments at both the token-level and sentence-level. Heatmaps indicate the degree of similarity, with darker colors representing greater distance and lower similarity.</span></h2></div> <p>
                    The live video comment generation task aims to generate human-like comments by understanding human behaviour. Typically, people post their comments according to current video content or contextual comments from other viewers. In this study, We propose a novel approach named &quot;VCMaster&quot; for multimodal live video comments generation, which involves three modalities to enrich the video information in complex social scenarios and focuses on improving generation quality and diversity, as depicted in Figure 1. 
                </p> <p>
                    We introduce a Hierarchical Cross-Fusion(HCF) Decoder to minimize the information loss during modality input and feature extraction process. Additionally, considering the consistency of the text structure of contextual comments with groundtruth comments, we decode contextual comments together with groundtruth in decoder and compute their attention weights by self-attention module. We also introduce a Sentence-Level Contrastive Loss (<common-latexDisplay>\mathcal{L}_{SCL}</common-latexDisplay>) to enlarge the distance between generated and contextual comments, forcing the model to generate diverse comments instead of relying too much on fed contextual comments. 
                </p></div></div></div></section> <section id="BibTeX" class="section"><div class="container is-max-desktop content"><h2 class="title publication-title">BibTeX</h2> <pre>        <code>
        @inproceedings{zhang2023vcmaster,
        title={VCMaster: Generating Diverse and Fluent Live Video Comments Based on Multimodal Contexts},
        author={Zhang, Manman and Luo, Ge and Ma, Yuchen and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
        booktitle={Proceedings of the 31th ACM International Conference on Multimedia},
        year={2023}
        }
        </code>
    </pre></div></section></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.e6a34b8f.js" defer></script><script src="/assets/js/2.cfd0c35e.js" defer></script><script src="/assets/js/1.bfcb5427.js" defer></script><script src="/assets/js/35.95e8af36.js" defer></script>
  </body>
</html>
